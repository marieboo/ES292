# Chapter 1: Golem of Prague

## 1.1. Statistical golem 
-- statistical models, models in general are programmed procedures (no thinking)

-- scientist as creators of models must select appropriate for context, otherwise they fail

-- standard statistical tests are fine, as long as we stay within well-tested context
e.g. linear regression, very specialized tests...


- BUT: classical tools are not diverse enough to handle common research questions

- Need: Rethinking 
"Statistical inference as set of strategies and not set of pre-made tools"

## 1.2. Statistical rethinking

Problems:

-- Choosing wrong tests

-- not understanding how tests work

-- concept misunderstanding: Purpose of stats testing is to falsify a Null hypothesis (Karl Popper)


### 1.2.1. Hypothesis are not models

Hypothesis are not models, therefore strict falsification impossible (weder hinreichend noch notwendig, logik!), Falsification is done to something other than the explanatory model (not always an opposite is possible, multi-criteria ptoblems)


### 1.2.2. Measurement matters

quality of method and data not absolute, Observation error (false positives, false negative), continuous hypotheses - not disproving/proving, but estimating

### 1.2.3 Falsification is consensual

but it is not logical

## 1.3. Tools for golem engineering

Instead of tests, we will have models as our tools

### 1.3.1. Bayesian data analysis

Pure logic, probabilities. Special case "Frequentist approach" - all probabibilities defined by events in large samples, parameters and models cannot have probability distribution, only a "sampling distribution exist" (?meaning? maybe that variability is not a probability and only uncertainty?)
Anyways, Bayesian statistics is logical and intuitive and that good.

### 1.3.2. Model comparison

Cross-Validation, Information Criteria will help with predictive accuracy, estimate of tendency of model to overfit data, spot influencial observations 

### 1.3.3. Multilevel models

uncertainty propagation happens, multilevel model help by using partial pooling (adjust estimates for repeat or imbalance in sampling, study variation, avoid averaging)

multilevel regression should always be norm over simple regression, but math hard

### 1.3.4. Graphical causal models

Cause and effect - wrong models may predict more accurately, but are still wrong!

Graphical Causal Model, Directed Acyclic Graph (DAG) will allow us to built a good statistical model, provided the causal model is true

## 1.4. Summary

math hard, statistics hard, logic good

Book parts
- 2,3 foundations Bayesian inference, basic tools, pure logic
- 4 to 9 multiple linear regression, causal inference when analyzing separate causal models for variable inclusion, plotting instead of interpreting, model complexity/overfitting, information theory and formal model comparison
- 9 to 12 linear models, markov chain monte carlo to fit models, maximum entropy, models, models, models
- 13 to 16 multi-level models, special models for error, missing data, spatial correlation, theoretical stats models